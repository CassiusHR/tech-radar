---
id: "reddit:1qvox18"
source: "reddit"
externalId: "1qvox18"
url: "https://www.reddit.com/r/LocalLLaMA/comments/1qvox18/interns1pro_1ta22b/"
title: "Intern-S1-Pro (1T/A22B)"
authorHandle: "ResearchCrafty1804"
authorName: "ResearchCrafty1804"
publishedAt: "2026-02-04T13:43:51.000Z"
fetchedAt: "2026-02-05T15:01:15.857Z"
tags: []
metrics: {"score":130,"comments":22,"subreddit":"LocalLLaMA"}
score: 6.949954718578075
scoreBreakdown: {"total":6.949954718578075,"recency":0.4914715460382752,"engagement":7.23070036349292,"author":0,"source":0.9}
---

ðŸš€Introducing Intern-S1-Pro, an advanced 1T MoE open-source multimodal scientific reasoning model.

\- SOTA scientific reasoning, competitive with leading closed-source models across AI4Science tasks.

\- Top-tier performance on advanced reasoning benchmarks, strong general multimodal performance on various benchmarks.

\- 1T-A22B MoE training efficiency with STE routing (dense gradient for router training) and grouped routing for stable convergence and balanced expert parallelism.

\- Fourier P
