---
id: "reddit:1qw5lbj"
source: "reddit"
externalId: "1qw5lbj"
url: "https://www.reddit.com/r/nextjs/comments/1qw5lbj/im_tired_of_paying_bills_for_my_blog_due_to/"
title: "Iâ€™m tired of paying bills for my blog, due to unwanted crawlers, so the only solution is a static export and custom Golang runtime"
authorHandle: "you-l-you"
authorName: "you-l-you"
publishedAt: "2026-02-05T00:05:24.000Z"
fetchedAt: "2026-02-05T15:01:15.857Z"
tags: ["pillar/nextjs"]
metrics: {"score":7,"comments":5,"subreddit":"nextjs"}
score: 4.18183099469244
scoreBreakdown: {"total":4.18183099469244,"recency":0.5999584219369695,"engagement":4.04652046105463,"author":0,"source":0.9}
---

I want to discuss the issue I faced recently. I have a small blog. It has some users: not more than 100 sessions per day. My CDN has a pay-as-you-go plan, so I pay for each GB of data loaded. The pricing isn't expensive, but the reality hits differently.

There are a lot of official crawlers from every search engine and AI companies. There are very strange unofficial crawlers. They gain a new IP every 10-20 requests: mostly from Singapore and China. They all crawled my little blog with fewer tha
